{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why We Need Ray Actors\n",
    "\n",
    "Using Ray tasks is great for distributing work around a cluster, but we've said nothing so far about managing distributed state, one of the big challenges in distributed computing. Ray tasks are excellent for stateless computation, but we need something for stateful computation. Python classes are a familiar mechanism for encapsulating state. Just as Ray tasks extend the familiar concept of Python functions, Ray addresses stateful computation by extending classes to become Ray actors.\n",
    "\n",
    "## What We Mean by Distributed State\n",
    "\n",
    "If you've worked with data processing libraries like Pandas or big data tools like Apache Spark, you know that they provide rich features for manipulating large, structured data sets, i.e., the analogs of tables in a database. Some tools even support partitioning of these data sets over clusters for scalability. This isn't the kind of distributed \"state\" Ray addresses. Instead, it's the more open-ended graph of objects found in more general-purpose applications. For example, it could be the state of a game engine used in a reinforcement learning (RL) application or the total set of parameters in a giant neural network, some of which now have hundreds of millions of parameters. In the following examples, we'll explore how Ray actors can be used to manage distributed state in various scenarios.\n",
    "\n",
    "# Monte Carlo Estimation of π\n",
    "This tutorial shows you how to estimate the value of π using a Monte Carlo method that works by randomly sampling points within a 2x2 square. We can use the proportion of the points that are contained within the unit circle centered at the origin to estimate the ratio of the area of the circle to the area of the square. Given that we know the true ratio to be π/4, we can multiply our estimated ratio by 4 to approximate the value of π. The more points that we sample to calculate this approximation, the closer the value should be to the true value of π."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Progress Actor\n",
    "\n",
    "Next, we define a Ray actor that can be called by sampling tasks to update progress. Ray actors are essentially stateful services that anyone with an instance (a handle) of the actor can call its methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class ProgressActor:\n",
    "    def __init__(self, total_num_samples: int):\n",
    "        self.total_num_samples = total_num_samples\n",
    "        self.num_samples_completed_per_task = {}\n",
    "\n",
    "    def report_progress(self, task_id: int, num_samples_completed: int) -> None:\n",
    "        self.num_samples_completed_per_task[task_id] = num_samples_completed\n",
    "\n",
    "    def get_progress(self) -> float:\n",
    "        return (\n",
    "            sum(self.num_samples_completed_per_task.values()) / self.total_num_samples\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a Ray actor by decorating a normal Python class with ray.remote. The progress actor has report_progress() method that will be called by sampling tasks to update their progress individually and get_progress() method to get the overall progress.\n",
    "\n",
    "## Defining the Sampling Task\n",
    "After our actor is defined, we now define a Ray task that does the sampling up to num_samples and returns the number of samples that are inside the circle. Ray tasks are stateless functions. They execute asynchronously, and run in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def sampling_task(num_samples: int, task_id: int,\n",
    "                  progress_actor: ray.actor.ActorHandle) -> int:\n",
    "    num_inside = 0\n",
    "    for i in range(num_samples):\n",
    "        x, y = random.uniform(-1, 1), random.uniform(-1, 1)\n",
    "        if math.hypot(x, y) <= 1:\n",
    "            num_inside += 1\n",
    "\n",
    "        # Report progress every 1 million samples.\n",
    "        if (i + 1) % 1_000_000 == 0:\n",
    "            # This is async.\n",
    "            progress_actor.report_progress.remote(task_id, i + 1)\n",
    "\n",
    "    # Report the final progress.\n",
    "    progress_actor.report_progress.remote(task_id, num_samples)\n",
    "    return num_inside"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we learnt in the `ray_tasks.ipynb` we can convert a normal Python function as a Ray task, we decorate the function with ray.remote. The sampling task takes a progress actor handle as an input and reports progress to it. The above code shows an example of calling actor methods from tasks.\n",
    "\n",
    "## Creating a Progress Actor\n",
    "Once the actor is defined, we can create an instance of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this to match your cluster scale.\n",
    "NUM_SAMPLING_TASKS = 10\n",
    "NUM_SAMPLES_PER_TASK = 10_000_000\n",
    "TOTAL_NUM_SAMPLES = NUM_SAMPLING_TASKS * NUM_SAMPLES_PER_TASK\n",
    "\n",
    "# Create the progress actor.\n",
    "progress_actor = ProgressActor.remote(TOTAL_NUM_SAMPLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create an instance of the progress actor, simply call ActorClass.remote() method with arguments to the constructor. This creates and runs the actor on a remote worker process. The return value of ActorClass.remote(...) is an actor handle that can be used to call its methods.\n",
    "\n",
    "## Executing Sampling Tasks\n",
    "Now the task is defined, we can execute it asynchronously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and execute all sampling tasks in parallel.\n",
    "results = [\n",
    "    sampling_task.remote(NUM_SAMPLES_PER_TASK, i, progress_actor)\n",
    "    for i in range(NUM_SAMPLING_TASKS)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We execute the sampling task by calling remote() method with arguments to the function. This immediately returns an ObjectRef as a future and then executes the function asynchronously on a remote worker process.\n",
    "\n",
    "## Calling the Progress Actor\n",
    "While sampling tasks are running, we can periodically query the progress by calling the actor get_progress() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query progress periodically.\n",
    "while True:\n",
    "    progress = ray.get(progress_actor.get_progress.remote())\n",
    "    print(f\"Progress: {int(progress * 100)}%\")\n",
    "\n",
    "    if progress == 1:\n",
    "        break\n",
    "\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To call an actor method, use actor_handle.method.remote(). This invocation immediately returns an ObjectRef as a future and then executes the method asynchronously on the remote actor process. To fetch the actual returned value of ObjectRef, we use the blocking ray.get().\n",
    "\n",
    "## Calculating π\n",
    "\n",
    "Finally, we get number of samples inside the circle from the remote sampling tasks and calculate π."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the sampling tasks results.\n",
    "total_num_inside = sum(ray.get(results))\n",
    "pi = (total_num_inside * 4) / TOTAL_NUM_SAMPLES\n",
    "print(f\"Estimated value of π is: {pi}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the above code, besides a single ObjectRef, ray.get() can also take a list of ObjectRef and return a list of results.\n",
    "\n",
    "If you run this tutorial, you will see output like:\n",
    "```bash\n",
    "Progress: 0%\n",
    "Progress: 15%\n",
    "Progress: 28%\n",
    "Progress: 40%\n",
    "Progress: 50%\n",
    "Progress: 60%\n",
    "Progress: 70%\n",
    "Progress: 80%\n",
    "Progress: 90%\n",
    "Progress: 100%\n",
    "Estimated value of π is: 3.1412202\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
